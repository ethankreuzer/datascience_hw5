{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "In this homework, we will explore finetuning two separate models:\n",
        "1. Distillbert for a sentiment classification task.\n",
        "2. The recent OpenLlama-2-3b model to turn it into a chatbot.\n"
      ],
      "metadata": {
        "id": "6UEW42VhzSyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the dependencies\n",
        "!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git"
      ],
      "metadata": {
        "id": "azYWyuWx17NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U datasets bitsandbytes einops"
      ],
      "metadata": {
        "id": "oH4I7pM7NA8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U fsspec==2023.9.2"
      ],
      "metadata": {
        "id": "P7lNkiYJNOtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distillbert for Sentiment Classification"
      ],
      "metadata": {
        "id": "BnATauHUz8uW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Deliverables:**\n",
        "\n",
        "Explore 2 different ways of tuning the model (# epochs, learning rate, weight decay, etc), in order to improve the classification perfomance. Detail the methodology that you followed for improving the performance of the model. A reasonable discusion on the approaches that you have taken is expected (points will be deducted for randomly changing the hyperparamenters of the model).\n",
        "\n",
        "You will have to include in your report your accuracy, precision, recall and f1 scores. Also, you have to include the image of your confusion matrix in heatmap form."
      ],
      "metadata": {
        "id": "JBl6VQFQB6m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "Gb5G0bNk1oeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "from datasets import load_dataset, Dataset, DatasetDict"
      ],
      "metadata": {
        "id": "Ckj4Q9kW1tmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataSet"
      ],
      "metadata": {
        "id": "7nzyJi7lJUCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_df = pd.read_csv(\"data/IMDB_dataset_clean.csv\")"
      ],
      "metadata": {
        "id": "1R7cEZ7hBV6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = train_test_split(imdb_df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "jOM9GZkL3Dpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(X_train, preserve_index=False),\n",
        "    \"test\": Dataset.from_pandas(X_test, preserve_index=False)\n",
        "    })"
      ],
      "metadata": {
        "id": "XlIgYLWqFzZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "-PcrjHIXBu85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True)\n",
        "\n",
        "# Tokenize the training and test sets\n",
        "train_tokenized = dataset[\"train\"].map(tokenize_function, batched=True)\n",
        "test_tokenized = dataset[\"test\"].map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "9F2u5qXJDAo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokenized, test_tokenized"
      ],
      "metadata": {
        "id": "Vu7RHGgEGNS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "TIV_-JFYGo_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the model"
      ],
      "metadata": {
        "id": "QG5MHgKAJl28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
      ],
      "metadata": {
        "id": "8CeDUlC_GrTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    probabilities = pred.predictions[:, 1]  # Assuming the probabilities for class 1\n",
        "\n",
        "    preds = (probabilities > 0.5).astype(int)  # Thresholding at 0.5 to determine class\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "    cm = confusion_matrix(labels, preds, labels=[0, 1])\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        \"y_true\": labels,\n",
        "        \"y_pred\": preds,\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1-score\": f1,\n",
        "        \"confusion_matrix\": cm\n",
        "    }"
      ],
      "metadata": {
        "id": "YIy_eDO2Gw-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=False,\n",
        "    push_to_hub=False,\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=test_tokenized,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "k0ZnpRAQG3uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()"
      ],
      "metadata": {
        "id": "tRunaKsaHGeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate()"
      ],
      "metadata": {
        "id": "iGZrY8aTI_K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your evaulation code here"
      ],
      "metadata": {
        "id": "-1ncQ5eAJHzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetune OpenLlama-2-3b\n",
        "The following shows how to fine-tune the recent OpenLlama-2-3b model on a single Google colab and turn it into a chatbot.\n",
        "\n",
        "We will leverage PEFT library from Hugging Face ecosystem, as well as QLoRA for more memory efficient finetuning.\n",
        "\n",
        "**Deliverables**\n",
        "1. Experiment with 3 different settings for LORA and create a line plot line plot with the r hyper parameter on the x-axis. Include a discussion on the effects of changing the hyperparameter.\n",
        "\n",
        "2. Write code to add one example to the dataset."
      ],
      "metadata": {
        "id": "imgHssi6BF0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "SGFaPwxiBjbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_name = 'gberseth/IFT6758-comments'\n",
        "dataset = load_dataset(dataset_name, split=\"train\")"
      ],
      "metadata": {
        "id": "F5cXNIBGAvbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "-hYDJGEVNpzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(lambda example: {'text': example['input'] + example['output']})"
      ],
      "metadata": {
        "id": "bP40uYdQAviK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "MNUEiboXNu6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Model"
      ],
      "metadata": {
        "id": "u9HdpDFFCJde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n",
        "\n",
        "model_name = \"openlm-research/open_llama_3b_v2\""
      ],
      "metadata": {
        "id": "s4ERwNnJCAmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")"
      ],
      "metadata": {
        "id": "LeDoLgeFChU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "model.config.use_cache = False"
      ],
      "metadata": {
        "id": "_UV1QUiWCiot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "EOzkiEOcCj9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_alpha = 8\n",
        "lora_dropout = 0.1\n",
        "lora_r = 8"
      ],
      "metadata": {
        "id": "wGwdASSTEsQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")"
      ],
      "metadata": {
        "id": "xlwVc75QExMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments"
      ],
      "metadata": {
        "id": "OOJhvD5wE0gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"./results\"\n",
        "per_device_train_batch_size = 1\n",
        "gradient_accumulation_steps = 2\n",
        "optim = \"paged_adamw_32bit\"\n",
        "save_steps = 1\n",
        "num_train_epochs = 4\n",
        "logging_steps = 1\n",
        "learning_rate = 2e-4\n",
        "max_grad_norm = 0.3\n",
        "max_steps = 200\n",
        "warmup_ratio = 0.03\n",
        "lr_scheduler_type = \"linear\""
      ],
      "metadata": {
        "id": "bbxYDRwbE40V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    fp16=True,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=\"none\",\n",
        ")"
      ],
      "metadata": {
        "id": "eM-jZqNDFBQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "id": "brStwghtFC3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 512"
      ],
      "metadata": {
        "id": "GmQN8F7kFE2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        ")"
      ],
      "metadata": {
        "id": "fRLXAyGdFGCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, module in trainer.model.named_modules():\n",
        "    if \"norm\" in name:\n",
        "        module = module.to(torch.float32)"
      ],
      "metadata": {
        "id": "H40gHk2aFZ-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()"
      ],
      "metadata": {
        "id": "LDj1P1diFeiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
        "model_to_save.save_pretrained(\"outputs\")"
      ],
      "metadata": {
        "id": "9qs8VNC9Hv8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig.from_pretrained('outputs')\n",
        "model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "id": "vqqTp9DTHxgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of text generation\n",
        "text = dataset['text'][5]\n",
        "device = \"cuda:0\"\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "outputs = model.generate(**inputs, max_new_tokens=50)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "qJsffCCTIauA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_-SfSVw9v-Xw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}